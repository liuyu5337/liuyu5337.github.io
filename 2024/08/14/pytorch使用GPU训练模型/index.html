

<!DOCTYPE html>
<html lang="zh-CN" data-default-color-scheme=auto>



<head>
  <meta charset="UTF-8">
  <link rel="apple-touch-icon" sizes="76x76" href="/img/fluid.png">
  <link rel="icon" href="/img/fluid.png">
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=5.0, shrink-to-fit=no">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  
  <meta name="theme-color" content="#2f4154">
  <meta name="author" content="zhq">
  <meta name="keywords" content="">
  
    <meta name="description" content="在深度学习中，使用GPU进行训练模型是必不可少。使用GPU训练模型的主要原因是GPU的并行处理能力和高吞吐量，主流的深度学习框架如Tensorflow、pytorch等都对GPU进行了优化。 CUDA  CUDA（Compute Unified Device Architecture）是由NVIDIA开发的用于并行计算的平台和编程模型。CUDA旨在利用NVIDIA GPU（图形处理单元）的强大计算">
<meta property="og:type" content="article">
<meta property="og:title" content="pytorch使用GPU训练模型">
<meta property="og:url" content="http://liuyu5337.github.io/2024/08/14/pytorch%E4%BD%BF%E7%94%A8GPU%E8%AE%AD%E7%BB%83%E6%A8%A1%E5%9E%8B/index.html">
<meta property="og:site_name" content="零壹网络">
<meta property="og:description" content="在深度学习中，使用GPU进行训练模型是必不可少。使用GPU训练模型的主要原因是GPU的并行处理能力和高吞吐量，主流的深度学习框架如Tensorflow、pytorch等都对GPU进行了优化。 CUDA  CUDA（Compute Unified Device Architecture）是由NVIDIA开发的用于并行计算的平台和编程模型。CUDA旨在利用NVIDIA GPU（图形处理单元）的强大计算">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="http://liuyu5337.github.io/2024/08/14/pytorch%E4%BD%BF%E7%94%A8GPU%E8%AE%AD%E7%BB%83%E6%A8%A1%E5%9E%8B/cuda-gpu.png">
<meta property="og:image" content="http://liuyu5337.github.io/2024/08/14/pytorch%E4%BD%BF%E7%94%A8GPU%E8%AE%AD%E7%BB%83%E6%A8%A1%E5%9E%8B/nvidia-smi.png">
<meta property="og:image" content="http://liuyu5337.github.io/2024/08/14/pytorch%E4%BD%BF%E7%94%A8GPU%E8%AE%AD%E7%BB%83%E6%A8%A1%E5%9E%8B/cuda.png">
<meta property="article:published_time" content="2024-08-14T01:58:33.000Z">
<meta property="article:modified_time" content="2024-08-14T03:42:24.181Z">
<meta property="article:author" content="zhq">
<meta name="twitter:card" content="summary_large_image">
<meta name="twitter:image" content="http://liuyu5337.github.io/2024/08/14/pytorch%E4%BD%BF%E7%94%A8GPU%E8%AE%AD%E7%BB%83%E6%A8%A1%E5%9E%8B/cuda-gpu.png">
  
  
    <meta name="referrer" content="no-referrer-when-downgrade">
  
  
  <title>pytorch使用GPU训练模型 - 零壹网络</title>

  <link  rel="stylesheet" href="https://lib.baomitu.com/twitter-bootstrap/4.6.1/css/bootstrap.min.css" />



  <link  rel="stylesheet" href="https://lib.baomitu.com/github-markdown-css/4.0.0/github-markdown.min.css" />

  <link  rel="stylesheet" href="https://lib.baomitu.com/hint.css/2.7.0/hint.min.css" />

  <link  rel="stylesheet" href="https://lib.baomitu.com/fancybox/3.5.7/jquery.fancybox.min.css" />



<!-- 主题依赖的图标库，不要自行修改 -->
<!-- Do not modify the link that theme dependent icons -->

<link rel="stylesheet" href="//at.alicdn.com/t/font_1749284_hj8rtnfg7um.css">



<link rel="stylesheet" href="//at.alicdn.com/t/font_1736178_lbnruvf0jn.css">


<link  rel="stylesheet" href="/css/main.css" />


  <link id="highlight-css" rel="stylesheet" href="/css/highlight.css" />
  
    <link id="highlight-css-dark" rel="stylesheet" href="/css/highlight-dark.css" />
  




  <script id="fluid-configs">
    var Fluid = window.Fluid || {};
    Fluid.ctx = Object.assign({}, Fluid.ctx)
    var CONFIG = {"hostname":"liuyu5337.github.io","root":"/","version":"1.9.7","typing":{"enable":true,"typeSpeed":70,"cursorChar":"_","loop":false,"scope":[]},"anchorjs":{"enable":true,"element":"h1,h2,h3,h4,h5,h6","placement":"left","visible":"hover","icon":""},"progressbar":{"enable":true,"height_px":3,"color":"#29d","options":{"showSpinner":false,"trickleSpeed":100}},"code_language":{"enable":true,"default":"TEXT"},"copy_btn":true,"image_caption":{"enable":true},"image_zoom":{"enable":true,"img_url_replace":["",""]},"toc":{"enable":true,"placement":"right","headingSelector":"h1,h2,h3,h4,h5,h6","collapseDepth":0},"lazyload":{"enable":true,"loading_img":"/img/loading.gif","onlypost":false,"offset_factor":2},"web_analytics":{"enable":false,"follow_dnt":true,"baidu":null,"google":{"measurement_id":null},"tencent":{"sid":null,"cid":null},"woyaola":null,"cnzz":null,"leancloud":{"app_id":null,"app_key":null,"server_url":null,"path":"window.location.pathname","ignore_local":false}},"search_path":"/local-search.xml","include_content_in_search":true};

    if (CONFIG.web_analytics.follow_dnt) {
      var dntVal = navigator.doNotTrack || window.doNotTrack || navigator.msDoNotTrack;
      Fluid.ctx.dnt = dntVal && (dntVal.startsWith('1') || dntVal.startsWith('yes') || dntVal.startsWith('on'));
    }
  </script>
  <script  src="/js/utils.js" ></script>
  <script  src="/js/color-schema.js" ></script>
  


  
<!-- hexo injector head_end start -->
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.css">

<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/hexo-math@4.0.0/dist/style.css">
<!-- hexo injector head_end end --><meta name="generator" content="Hexo 7.3.0"></head>


<body>
  

  <header>
    

<div class="header-inner" style="height: 70vh;">
  <nav id="navbar" class="navbar fixed-top  navbar-expand-lg navbar-dark scrolling-navbar">
  <div class="container">
    <a class="navbar-brand" href="/">
      <strong>零壹网络</strong>
    </a>

    <button id="navbar-toggler-btn" class="navbar-toggler" type="button" data-toggle="collapse"
            data-target="#navbarSupportedContent"
            aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation">
      <div class="animated-icon"><span></span><span></span><span></span></div>
    </button>

    <!-- Collapsible content -->
    <div class="collapse navbar-collapse" id="navbarSupportedContent">
      <ul class="navbar-nav ml-auto text-center">
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/" target="_self">
                <i class="iconfont icon-home-fill"></i>
                <span>首页</span>
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/archives/" target="_self">
                <i class="iconfont icon-archive-fill"></i>
                <span>归档</span>
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/categories/" target="_self">
                <i class="iconfont icon-category-fill"></i>
                <span>分类</span>
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/tags/" target="_self">
                <i class="iconfont icon-tags-fill"></i>
                <span>标签</span>
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/about/" target="_self">
                <i class="iconfont icon-user-fill"></i>
                <span>关于</span>
              </a>
            </li>
          
        
        
          <li class="nav-item" id="search-btn">
            <a class="nav-link" target="_self" href="javascript:;" data-toggle="modal" data-target="#modalSearch" aria-label="Search">
              <i class="iconfont icon-search"></i>
            </a>
          </li>
          
        
        
          <li class="nav-item" id="color-toggle-btn">
            <a class="nav-link" target="_self" href="javascript:;" aria-label="Color Toggle">
              <i class="iconfont icon-dark" id="color-toggle-icon"></i>
            </a>
          </li>
        
      </ul>
    </div>
  </div>
</nav>

  

<div id="banner" class="banner" parallax=true
     style="background: url('/img/default.png') no-repeat center center; background-size: cover;">
  <div class="full-bg-img">
    <div class="mask flex-center" style="background-color: rgba(0, 0, 0, 0.3)">
      <div class="banner-text text-center fade-in-up">
        <div class="h2">
          
            <span id="subtitle" data-typed-text="pytorch使用GPU训练模型"></span>
          
        </div>

        
          
  <div class="mt-3">
    
    
      <span class="post-meta">
        <i class="iconfont icon-date-fill" aria-hidden="true"></i>
        <time datetime="2024-08-14 09:58" pubdate>
          2024年8月14日 上午
        </time>
      </span>
    
  </div>

  <div class="mt-1">
    
      <span class="post-meta mr-2">
        <i class="iconfont icon-chart"></i>
        
          3.1k 字
        
      </span>
    

    
      <span class="post-meta mr-2">
        <i class="iconfont icon-clock-fill"></i>
        
        
        
          26 分钟
        
      </span>
    

    
    
  </div>


        
      </div>

      
    </div>
  </div>
</div>

</div>

  </header>

  <main>
    
      

<div class="container-fluid nopadding-x">
  <div class="row nomargin-x">
    <div class="side-col d-none d-lg-block col-lg-2">
      

    </div>

    <div class="col-lg-8 nopadding-x-md">
      <div class="container nopadding-x-md" id="board-ctn">
        <div id="board">
          <article class="post-content mx-auto">
            <h1 id="seo-header">pytorch使用GPU训练模型</h1>
            
            
              <div class="markdown-body">
                
                <p>在深度学习中，使用GPU进行训练模型是必不可少。使用GPU训练模型的主要原因是GPU的并行处理能力和高吞吐量，主流的深度学习框架如Tensorflow、pytorch等都对GPU进行了优化。</p>
<h4 id="cuda">CUDA</h4>
<hr />
<p>CUDA（Compute Unified Device
Architecture）是由NVIDIA开发的用于并行计算的平台和编程模型。CUDA旨在利用NVIDIA
GPU（图形处理单元）的强大计算能力来加速各种科学计算、数值模拟和深度学习任务。</p>
<p>CUDA的软件堆栈由驱动层、运行时层和函数库层构成。CUDA软件堆栈中涉及的API包括驱动层API和运行时层API。</p>
<p>CUDA是显卡厂商NVIDIA在2007年推出的并行计算平台和编程模型。CUDA利用图形处理器GPU（Graphics
Processing Unit），可显著提高计算性能。</p>
<p>下图展示CUDA的架构体系。CUDA软件堆栈中的驱动层API和运行时层API的区别如下。</p>
<ul>
<li>驱动层API（Driver API）：功能较完整，但是使用复杂。</li>
<li>运行时API（CUDA Runtime
API）：封装了部分驱动的API，将某些驱动初始化操作隐藏，使用方便。</li>
</ul>
<p>CUDA的Driver API由<a
target="_blank" rel="noopener" href="https://www.nvidia.com/Download/index.aspx">NVIDIA
Driver</a>包提供，而CUDA Library和CUDA Runtime由<a
target="_blank" rel="noopener" href="https://developer.nvidia.com/cuda-toolkit">CUDA
Toolkit</a>包提供。</p>
<p><img src="cuda-gpu.png" srcset="/img/loading.gif" lazyload style="zoom:50%;" /></p>
<p><strong>CUDA的作用和特点:</strong></p>
<ol type="1">
<li><strong>「GPU并行计算」</strong>：
CUDA使GPU能够执行并行计算任务，从而大幅提高了计算性能。GPU由许多小型处理单元组成，每个处理单元都能够执行多个线程，这意味着GPU可以同时处理大量的计算任务。</li>
<li><strong>「CUDA编程模型」</strong>：
CUDA提供了一种编程模型，允许开发人员编写C/C++代码，利用GPU的并行性来执行任务。开发人员可以编写称为"核函数"（kernel）的代码，这些核函数在GPU上并行执行。CUDA编程模型还提供了一组API（应用程序接口）来管理GPU内存、控制GPU设备和调度核函数的执行。</li>
<li>「并行计算应用」：
CUDA广泛用于各种领域的科学计算和高性能计算应用，包括：
<ul>
<li><strong>「数值模拟」</strong>：CUDA可用于模拟物理现象、天气模型、流体力学等领域的数值模拟。</li>
<li><strong>「深度学习」</strong>：深度学习框架如TensorFlow和PyTorch都支持CUDA，可用于训练和推理深度神经网络，加速图像识别、自然语言处理等任务。</li>
<li><strong>「分子动力学」</strong>：用于模拟分子之间相互作用，有助于药物设计和材料科学研究。</li>
<li><strong>「地球科学」</strong>：用于地震模拟、气象学、地球物理学等领域的大规模数值模拟。</li>
</ul></li>
<li><strong>「NVIDIA GPU支持」</strong>： CUDA仅适用于NVIDIA
GPU。不同版本的CUDA通常与特定型号的NVIDIA
GPU兼容，因此需要确保你的GPU支持所选版本的CUDA。</li>
<li><strong>「CUDA工具和库」</strong>：
NVIDIA提供了一套用于CUDA开发的工具和库，包括CUDA
Toolkit、cuDNN（CUDA深度神经网络库）、cuBLAS（CUDA基础线性代数库）等。这些工具和库简化了CUDA应用程序的开发和优化过程。</li>
</ol>
<h4 id="cudnn">cuDNN</h4>
<hr />
<p>cuDNN（CUDA Deep Neural Network
Library）是由NVIDIA开发的用于深度学习的加速库。cuDNN旨在优化神经网络的前向传播和反向传播过程，以利用NVIDIA
GPU的并行计算能力，从而加速深度学习模型的训练和推理。</p>
<p><strong>cuDNN的作用特点：</strong></p>
<ol type="1">
<li><strong>「深度学习加速」</strong>：
cuDNN是专门为深度学习任务而设计的，旨在加速神经网络的训练和推理。它提供了一系列高度优化的算法和函数，用于执行神经网络层的前向传播、反向传播和权重更新。</li>
<li><strong>「GPU加速」</strong>： cuDNN充分利用NVIDIA
GPU的并行计算能力，以高效地执行深度学习操作。这使得训练深度神经网络更快速，尤其是对于大型模型和大规模数据集。</li>
<li><strong>「深度学习框架支持」</strong>：
cuDNN被广泛用于多个深度学习框架，包括TensorFlow、PyTorch、Caffe、MXNet等。这些框架通过cuDNN来加速模型的训练和推理过程，使得深度学习研究和开发更加高效。</li>
<li><strong>「提高性能」</strong>：
cuDNN通过使用高度优化的卷积和池化算法、自动混合精度计算、内存管理和多GPU支持等技术，显著提高了深度学习任务的性能。这些优化可以加速卷积神经网络（CNN）、循环神经网络（RNN）、生成对抗网络（GAN）等各种类型的神经网络。</li>
<li><strong>「版本兼容性」</strong>： cuDNN的不同版本与NVIDIA
GPU架构和深度学习框架的版本兼容。因此，为了获得最佳性能，你需要选择适用于你的GPU型号和深度学习框架版本的cuDNN版本。</li>
<li><strong>「免费使用」</strong>：
cuDNN是免费的，可以在NVIDIA的官方网站上下载和使用。</li>
</ol>
<h4 id="pytorch">Pytorch</h4>
<hr />
<p>PyTorch
是一个开源的深度学习框架，由Facebook的人工智能研究团队开发和维护。它是一个非常流行的深度学习框架，用于构建和训练神经网络模型。</p>
<p><strong>pytorch的作用和特点:</strong></p>
<ol type="1">
<li><strong>「动态计算图」</strong>： PyTorch 采用动态计算图（Dynamic
Computational
Graph）的方式来定义和执行神经网络。这意味着你可以像编写常规Python代码一样编写神经网络，同时保留了计算图的优势，使模型的构建和调试更加直观和灵活。</li>
<li><strong>「灵活性」</strong>： PyTorch
提供了丰富的张量操作，以及各种优化工具和模块，可以轻松构建各种类型的深度学习模型，包括卷积神经网络（CNN）、循环神经网络（RNN）、生成对抗网络（GAN）等。它还支持自定义神经网络层和损失函数，允许你创建高度定制的模型。</li>
<li><strong>「GPU加速」</strong>：
PyTorch天然支持GPU加速，你可以在GPU上训练和执行神经网络，大幅提高了计算性能。PyTorch的GPU张量操作与CPU张量操作非常相似，使得将计算从CPU迁移到GPU变得相对容易。</li>
<li><strong>「动态调试」</strong>：
由于采用动态计算图，PyTorch允许你在模型构建和训练过程中轻松进行动态调试，检查梯度、查看中间变量等。这对于理解和诊断模型行为非常有帮助。</li>
<li><strong>「丰富的生态系统」</strong>：
PyTorch拥有庞大的用户社区，有许多开源项目、库和工具，可以扩展其功能。这些包括模型部署工具、迁移学习库、自然语言处理工具和计算机视觉工具，以及与其他深度学习框架的集成。</li>
<li><strong>「深度学习研究和教育」</strong>：
PyTorch在深度学习研究和教育中非常流行，因为它易于学习、易于使用，并提供了丰富的教程和文档资源。它还被许多大学和研究机构用于深度学习课程和研究项目。</li>
<li><strong>「跨平台支持」</strong>：
PyTorch支持多种操作系统，包括Linux、macOS和Windows，以及多种编程语言接口，如Python、C++等。这使得它适用于各种应用场景。</li>
</ol>
<h4 id="cudacudnnpytorch的关系">CUDA、cuDNN、Pytorch的关系</h4>
<hr />
<p>CUDA、cuDNN 和 PyTorch
是三个不同但相关的组件，它们之间存在一些依赖关系，</p>
<ol type="1">
<li>「CUDA（Compute Unified Device Architecture）」:
<ul>
<li><strong>「CUDA是GPU并行计算平台」</strong>：CUDA 是由 NVIDIA
开发的用于并行计算的平台和编程模型。它允许开发人员利用 NVIDIA GPU
的强大计算能力来加速各种科学计算、数值模拟和深度学习任务。</li>
<li><strong>「PyTorch依赖CUDA」</strong>：PyTorch 使用 CUDA
来加速神经网络的训练和推理。在 PyTorch 中，张量（Tensor）可以在 CPU 或
GPU 上进行计算。如果你想在 GPU 上训练神经网络，你需要确保 CUDA
已经正确安装并配置。</li>
<li><strong>「版本兼容性」</strong>：不同版本的 PyTorch
可能需要特定版本的 CUDA。你需要根据所使用的 PyTorch 版本来选择合适的
CUDA 版本，以确保兼容性。</li>
</ul></li>
<li>「cuDNN（CUDA Deep Neural Network Library）」:
<ul>
<li><strong>「cuDNN用于深度学习加速」</strong>：cuDNN 是 NVIDIA
开发的专门用于深度学习的加速库。它提供了高度优化的卷积和其他深度神经网络层的操作，以提高深度学习模型的性能。</li>
<li><strong>「PyTorch依赖cuDNN」</strong>：PyTorch 使用 cuDNN
来执行深度学习操作，尤其是在卷积神经网络（CNN）中。cuDNN
提供了高性能的卷积操作，使 PyTorch 能够在 GPU
上高效地进行前向传播和反向传播。</li>
<li><strong>「版本兼容性」</strong>：不同版本的 PyTorch 需要特定版本的
cuDNN。你需要确保所使用的 cuDNN 版本与 PyTorch 版本兼容。</li>
</ul></li>
<li>「PyTorch」:
<ul>
<li><strong>「PyTorch是深度学习框架」</strong>：PyTorch
是一个开源的深度学习框架，用于构建、训练和部署神经网络模型。它提供了张量操作、自动求导、优化器、损失函数等工具，使深度学习任务更加便捷。</li>
<li><strong>「PyTorch依赖CUDA和cuDNN」</strong>：PyTorch 可以在 CPU 或
GPU 上运行，但为了获得最佳性能，特别是在大规模深度学习任务中，你通常会将
PyTorch 配置为在 GPU 上运行。这就需要确保 CUDA 和 cuDNN
已正确安装和配置。</li>
</ul></li>
</ol>
<h4 id="查看cuda">查看CUDA</h4>
<hr />
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> torch<br><span class="hljs-built_in">print</span>(torch.cuda.is_available())<br><span class="hljs-built_in">print</span>(torch.cuda.get_arch_list())<br>torch.zeros(<span class="hljs-number">1</span>).cuda()<br></code></pre></td></tr></table></figure>
<p>输出:</p>
<figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs stylus">True<br><span class="hljs-selector-attr">[<span class="hljs-string">&#x27;sm_37&#x27;</span>, <span class="hljs-string">&#x27;sm_50&#x27;</span>, <span class="hljs-string">&#x27;sm_60&#x27;</span>, <span class="hljs-string">&#x27;sm_70&#x27;</span>, <span class="hljs-string">&#x27;sm_75&#x27;</span>, <span class="hljs-string">&#x27;sm_80&#x27;</span>, <span class="hljs-string">&#x27;sm_86&#x27;</span>]</span><br><span class="hljs-function"><span class="hljs-title">tensor</span><span class="hljs-params">([<span class="hljs-number">0</span>.], device=<span class="hljs-string">&#x27;cuda:0&#x27;</span>)</span></span><br></code></pre></td></tr></table></figure>
<p>torch.cuda.is_available() 为True 说明CUDA是可用的，如果为False
就要检查pytorch的版本与CUDA的版本是否兼容一致。</p>
<p>torch.cuda.get_arch_list() 返回的是CUDA
架构列表。也就是说CUDA能支持的GPU的架构，不同版本的CUDA支持的GPU是不一样的，所以一定要根据GPU的型号/架构来选择要安装的CUDA版本.</p>
<p>如果cuda版本和GPU兼容，则<code>torch.zeros(1).cuda()</code>
在GPU上运算就会成功，否则就会报错。</p>
<p>如果安装了GPU显卡驱动：在命令行执行以下命令</p>
<figure class="highlight ebnf"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs ebnf"><span class="hljs-attribute">nvidia-smi</span><br></code></pre></td></tr></table></figure>
<p><img src="nvidia-smi.png" srcset="/img/loading.gif" lazyload alt="nvidia-smi" style="zoom:50%;" /></p>
<p>从上图可以知道安装的驱动版本为550.78，驱动API版本为12.4，表示该驱动最高支持CUDA运行时API版本为12.4。显卡是GeForce
RTX 3090,24G显存。</p>
<p>根据上述信息，从nvidia的网站上就可以找到对应的<a
target="_blank" rel="noopener" href="https://docs.nvidia.com/cuda/cuda-toolkit-release-notes/index.html?spm=a2c4g.207292.0.0.62f2778erY9RgV">CUDA版本</a>。</p>
<h4 id="pytorch的安装">PyTorch的安装</h4>
<hr />
<p>在pytorch的<a
target="_blank" rel="noopener" href="https://pytorch.org/">官方网站</a>上可以找到pytorch的安装说明。如果需要安装其他版本pytorch和对应的cuda版本，可以在<a
target="_blank" rel="noopener" href="https://pytorch.org/get-started/previous-versions/">这里</a>找到。从这个页面找到对应的pytorch版本，并选择相应的系统，执行对应的命令即可。</p>
<p>如需要安装cuda=11.6 pytorch=1.12.0 torchvision=0.13.0
torchaudio=0.12.0就可以执行如下命令进行安装</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">pip install torch==1.12.0+cu116 torchvision==0.13.0+cu116 torchaudio==0.12.0 --extra-index-url https://download.pytorch.org/whl/cu116<br></code></pre></td></tr></table></figure>
<p>关于GPU架构和CUDA算力的关系,可以查看<a
target="_blank" rel="noopener" href="https://cuiyuhao.com/posts/8a630bae/">这篇文章</a></p>
<h4 id="pytorch在gpu上训练的方法">pytorch在GPU上训练的方法</h4>
<hr />
<p>方法一 .cuda()</p>
<p>我们可以通过对网络模型，数据，损失函数这三种变量调用 .cuda()
来在GPU上进行训练.</p>
<p><img src="cuda.png" srcset="/img/loading.gif" lazyload style="zoom:50%;" /></p>
<p>比如:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># 将网络模型在gpu上训练</span><br>model = Model()<br><span class="hljs-keyword">if</span> torch.cuda.is_available(): <span class="hljs-comment"># 判断 cuda 是否可用</span><br>	model = model.cuda()<br><br><span class="hljs-comment"># 损失函数在gpu上训练</span><br>loss_fn = nn.CrossEntropyLoss()<br><span class="hljs-keyword">if</span> torch.cuda.is_available():	 <span class="hljs-comment"># 判断 cuda 是否可用</span><br>	loss_fn = loss_fn.cuda()<br><br><span class="hljs-comment"># 数据在gpu上训练</span><br><span class="hljs-keyword">for</span> data <span class="hljs-keyword">in</span> dataloader:                        <br>	imgs, targets = data<br>    <span class="hljs-keyword">if</span> torch.cuda.is_available(): <span class="hljs-comment"># 判断 cuda 是否可用</span><br>        imgs = imgs.cuda()<br>        targets = targets.cuda()<br><br></code></pre></td></tr></table></figure>
<p>方法二 .to(device)</p>
<p>指定训练设备:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs python">device = torch.device(<span class="hljs-string">&quot;cpu&quot;</span>)	<span class="hljs-comment"># 使用cpu训练</span><br>device = torch.device(<span class="hljs-string">&quot;cuda&quot;</span>)	<span class="hljs-comment"># 使用gpu训练 </span><br>device = torch.device(<span class="hljs-string">&quot;cuda:0&quot;</span>)	<span class="hljs-comment"># 当电脑中有多张显卡时，使用第一张显卡</span><br>device = torch.device(<span class="hljs-string">&quot;cuda:1&quot;</span>)	<span class="hljs-comment"># 当电脑中有多张显卡时，使用第二张显卡</span><br><br>device = torch.device(<span class="hljs-string">&quot;cuda&quot;</span> <span class="hljs-keyword">if</span> torch.cuda.is_available() <span class="hljs-keyword">else</span> <span class="hljs-string">&quot;cpu&quot;</span>)<br></code></pre></td></tr></table></figure>
<p>使用GPU训练</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs python">model = model.to(device)<br><br>loss_fn = loss_fn.to(device)<br><br><span class="hljs-keyword">for</span> data <span class="hljs-keyword">in</span> train_dataloader:<br>    imgs, targets = data<br>    imgs = imgs.to(device)<br>    targets = targets.to(device)<br><br></code></pre></td></tr></table></figure>
<h4 id="qa">Q&amp;A</h4>
<ol type="1">
<li><p>CUDA error: no kernel image is available for execution on the
device</p>
<p>当前GPU的算力与当前版本的Pytorch依赖的CUDA算力不匹配。</p>
<p>解决：需要根据显卡的cuda版本，重新安装pytorch的版本.</p></li>
<li><p>Expected all tensors to be on the same device, but found at least
two devices, cuda:0 and cpu! (when checking argument for argument index
in method wrapper__index_select)</p>
<p>原因：参与运算的两个或多个变量，有的在CPU上，有的在GPU上</p>
<p>解决方案:
先找到报错的行，看看计算时都用到哪些变量或者数据，然后在调试模式下使用.is_cuda这个属性去查看到底哪些是在GPU上，哪些是在CPU上，然后把它们统一都放在CPU，或者统一放在GPU上就可以。如果增加了变量，需要将新增加的变量也搬到GPU上去。</p></li>
</ol>

                
              </div>
            
            <hr/>
            <div>
              <div class="post-metas my-3">
  
    <div class="post-meta mr-3 d-flex align-items-center">
      <i class="iconfont icon-category"></i>
      

<span class="category-chains">
  
  
    
      <span class="category-chain">
        
  <a href="/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E6%8A%80%E6%9C%AF/" class="category-chain-item">计算机技术</a>
  
  
    <span>></span>
    
  <a href="/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E6%8A%80%E6%9C%AF/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/" class="category-chain-item">深度学习</a>
  
  
    <span>></span>
    
  <a href="/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E6%8A%80%E6%9C%AF/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/pytorch/" class="category-chain-item">pytorch</a>
  
  

  

  

      </span>
    
  
</span>

    </div>
  
  
</div>


              

              
                <div class="post-prevnext my-3">
                  <article class="post-prev col-6">
                    
                    
                      <a href="/2024/08/15/matplotlib%E4%B8%AD%E7%9A%84%E4%B8%AD%E6%96%87%E5%AD%97%E4%BD%93%E8%AE%BE%E7%BD%AE/" title="matplotlib中的中文字体设置">
                        <i class="iconfont icon-arrowleft"></i>
                        <span class="hidden-mobile">matplotlib中的中文字体设置</span>
                        <span class="visible-mobile">上一篇</span>
                      </a>
                    
                  </article>
                  <article class="post-next col-6">
                    
                    
                      <a href="/2024/08/07/pytorch%E7%9A%84model-train-%E4%B8%8Emodel-eval/" title="pytorch的model.train()与model.eval()">
                        <span class="hidden-mobile">pytorch的model.train()与model.eval()</span>
                        <span class="visible-mobile">下一篇</span>
                        <i class="iconfont icon-arrowright"></i>
                      </a>
                    
                  </article>
                </div>
              
            </div>

            
          </article>
        </div>
      </div>
    </div>

    <div class="side-col d-none d-lg-block col-lg-2">
      
  <aside class="sidebar" style="margin-left: -1rem">
    <div id="toc">
  <p class="toc-header">
    <i class="iconfont icon-list"></i>
    <span>目录</span>
  </p>
  <div class="toc-body" id="toc-body"></div>
</div>



  </aside>


    </div>
  </div>
</div>





  



  



  



  



  







    

    
      <a id="scroll-top-button" aria-label="TOP" href="#" role="button">
        <i class="iconfont icon-arrowup" aria-hidden="true"></i>
      </a>
    

    
      <div class="modal fade" id="modalSearch" tabindex="-1" role="dialog" aria-labelledby="ModalLabel"
     aria-hidden="true">
  <div class="modal-dialog modal-dialog-scrollable modal-lg" role="document">
    <div class="modal-content">
      <div class="modal-header text-center">
        <h4 class="modal-title w-100 font-weight-bold">搜索</h4>
        <button type="button" id="local-search-close" class="close" data-dismiss="modal" aria-label="Close">
          <span aria-hidden="true">&times;</span>
        </button>
      </div>
      <div class="modal-body mx-3">
        <div class="md-form mb-5">
          <input type="text" id="local-search-input" class="form-control validate">
          <label data-error="x" data-success="v" for="local-search-input">关键词</label>
        </div>
        <div class="list-group" id="local-search-result"></div>
      </div>
    </div>
  </div>
</div>

    

    
  </main>

  <footer>
    <div class="footer-inner">
  
    <div class="footer-content">
       <a href="https://hexo.io" target="_blank" rel="nofollow noopener"><span>Hexo</span></a> <i class="iconfont icon-love"></i> <a href="https://github.com/fluid-dev/hexo-theme-fluid" target="_blank" rel="nofollow noopener"><span>Fluid</span></a> 
    </div>
  
  
    <div class="statistics">
  
  

  
    
      <span id="busuanzi_container_site_pv" style="display: none">
        总访问量 
        <span id="busuanzi_value_site_pv"></span>
         次
      </span>
    
    
      <span id="busuanzi_container_site_uv" style="display: none">
        总访客数 
        <span id="busuanzi_value_site_uv"></span>
         人
      </span>
    
    
  
</div>

  
  
  
</div>

  </footer>

  <!-- Scripts -->
  
  <script  src="https://lib.baomitu.com/nprogress/0.2.0/nprogress.min.js" ></script>
  <link  rel="stylesheet" href="https://lib.baomitu.com/nprogress/0.2.0/nprogress.min.css" />

  <script>
    NProgress.configure({"showSpinner":false,"trickleSpeed":100})
    NProgress.start()
    window.addEventListener('load', function() {
      NProgress.done();
    })
  </script>


<script  src="https://lib.baomitu.com/jquery/3.6.4/jquery.min.js" ></script>
<script  src="https://lib.baomitu.com/twitter-bootstrap/4.6.1/js/bootstrap.min.js" ></script>
<script  src="/js/events.js" ></script>
<script  src="/js/plugins.js" ></script>


  <script  src="https://lib.baomitu.com/typed.js/2.0.12/typed.min.js" ></script>
  <script>
    (function (window, document) {
      var typing = Fluid.plugins.typing;
      var subtitle = document.getElementById('subtitle');
      if (!subtitle || !typing) {
        return;
      }
      var text = subtitle.getAttribute('data-typed-text');
      
        typing(text);
      
    })(window, document);
  </script>




  
    <script  src="/js/img-lazyload.js" ></script>
  




  
<script>
  Fluid.utils.createScript('https://lib.baomitu.com/tocbot/4.20.1/tocbot.min.js', function() {
    var toc = jQuery('#toc');
    if (toc.length === 0 || !window.tocbot) { return; }
    var boardCtn = jQuery('#board-ctn');
    var boardTop = boardCtn.offset().top;

    window.tocbot.init(Object.assign({
      tocSelector     : '#toc-body',
      contentSelector : '.markdown-body',
      linkClass       : 'tocbot-link',
      activeLinkClass : 'tocbot-active-link',
      listClass       : 'tocbot-list',
      isCollapsedClass: 'tocbot-is-collapsed',
      collapsibleClass: 'tocbot-is-collapsible',
      scrollSmooth    : true,
      includeTitleTags: true,
      headingsOffset  : -boardTop,
    }, CONFIG.toc));
    if (toc.find('.toc-list-item').length > 0) {
      toc.css('visibility', 'visible');
    }

    Fluid.events.registerRefreshCallback(function() {
      if ('tocbot' in window) {
        tocbot.refresh();
        var toc = jQuery('#toc');
        if (toc.length === 0 || !tocbot) {
          return;
        }
        if (toc.find('.toc-list-item').length > 0) {
          toc.css('visibility', 'visible');
        }
      }
    });
  });
</script>


  <script src=https://lib.baomitu.com/clipboard.js/2.0.11/clipboard.min.js></script>

  <script>Fluid.plugins.codeWidget();</script>


  
<script>
  Fluid.utils.createScript('https://lib.baomitu.com/anchor-js/4.3.1/anchor.min.js', function() {
    window.anchors.options = {
      placement: CONFIG.anchorjs.placement,
      visible  : CONFIG.anchorjs.visible
    };
    if (CONFIG.anchorjs.icon) {
      window.anchors.options.icon = CONFIG.anchorjs.icon;
    }
    var el = (CONFIG.anchorjs.element || 'h1,h2,h3,h4,h5,h6').split(',');
    var res = [];
    for (var item of el) {
      res.push('.markdown-body > ' + item.trim());
    }
    if (CONFIG.anchorjs.placement === 'left') {
      window.anchors.options.class = 'anchorjs-link-left';
    }
    window.anchors.add(res.join(', '));

    Fluid.events.registerRefreshCallback(function() {
      if ('anchors' in window) {
        anchors.removeAll();
        var el = (CONFIG.anchorjs.element || 'h1,h2,h3,h4,h5,h6').split(',');
        var res = [];
        for (var item of el) {
          res.push('.markdown-body > ' + item.trim());
        }
        if (CONFIG.anchorjs.placement === 'left') {
          anchors.options.class = 'anchorjs-link-left';
        }
        anchors.add(res.join(', '));
      }
    });
  });
</script>


  
<script>
  Fluid.utils.createScript('https://lib.baomitu.com/fancybox/3.5.7/jquery.fancybox.min.js', function() {
    Fluid.plugins.fancyBox();
  });
</script>


  <script>Fluid.plugins.imageCaption();</script>

  <script  src="/js/local-search.js" ></script>

  <script defer src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js" ></script>





<!-- 主题的启动项，将它保持在最底部 -->
<!-- the boot of the theme, keep it at the bottom -->
<script  src="/js/boot.js" ></script>


  

  <noscript>
    <div class="noscript-warning">博客在允许 JavaScript 运行的环境下浏览效果更佳</div>
  </noscript>
</body>
</html>
